{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys, signal,rospy, argparse, csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.distance import cdist\n",
    "import copy, pickle\n",
    "import open3d as o3d\n",
    "import open3d.visualization as vis\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from open3d_ros_helper import open3d_ros_helper as orh\n",
    "from geometry_msgs.msg import Pose, PoseArray, Point # PoseArray, Pose\n",
    "\n",
    "from models.mdgat_Rops2 import MDGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Point cloud matching and pose evaluation',\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "opt = argparse.Namespace(\n",
    "    dataset_dir = '/media/vision/Seagate/DataSets/denseKITTI',\n",
    "    # slam_dir = '',\n",
    "    data_folder = 'harris_3D',\n",
    "    local_global = False,\n",
    "    seq_num = 0,\n",
    "    visualize = False,\n",
    "    vis_line_width = 0.2,\n",
    "    calculate_pose = True,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 1,\n",
    "    train_path = './denseKITTI/',\n",
    "    model_out_path = './models/checkpoint',\n",
    "    memory_is_enough = True,\n",
    "    local_rank = 0,\n",
    "    txt_path = './KITTI/preprocess-random-full',\n",
    "    keypoints_path = './denseKITTI/keypoints',\n",
    "    resume_model = './checkpoint/denseKITTI/mdgat-l9-gap_loss-Rops-05_16_15_44/nomutualcheck-mdgat-batch128-lr0.001-gap_loss-Rops-Hariss3D-05_16_15_44/best_model_epoch_83(val_loss0.0859988382121983).pth',\n",
    "    loss_method = 'triplet_loss',\n",
    "    net = 'mdgat',\n",
    "    mutual_check = False,\n",
    "    k = [128, None, 128, None, 64, None, 64, None],\n",
    "    l = 9,\n",
    "    descriptor = 'Rops',\n",
    "    keypoints = 'harris_3D',\n",
    "    ensure_kpts_num = False,\n",
    "    max_keypoints = -1,\n",
    "    match_threshold = 0.2,\n",
    "    threshold = 0.5,\n",
    "    triplet_loss_gamma = 0.5,\n",
    "    sinkhorn_iterations = 20,\n",
    "    train_step = 3,\n",
    "\n",
    "    fpfh_normal_radiuse = 0.3,\n",
    "    fpfh_descriptors_radiuse = 1.0,\n",
    "    seq_list = [0],\n",
    "    mdgat_path = './KITTI',\n",
    "    kitti_path = '/media/vision/Seagate/DataSets/kitti/dataset/sequences',\n",
    "    transform_opt = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kitti_Rops_dataset_loader():\n",
    "    def __init__(self, args) -> None:\n",
    "        self.dataset_dir = args.dataset_dir\n",
    "        self.seq = args.seq_num\n",
    "        self.descriptor_type = args.descriptor\n",
    "\n",
    "        self.gt_pairs = []\n",
    "        self.poses = []\n",
    "        self.keypoints = []\n",
    "        self.scores = []\n",
    "        self.descriptors = []\n",
    "        self.dense_scans = []\n",
    "\n",
    "        self.local_graph_range = [0, 0]\n",
    "        self.divided_keypoints = np.array([])\n",
    "        self.divided_dense_scans = []\n",
    "        self.divided_seq_num = 0\n",
    "\n",
    "        self._load_gt_pairs()\n",
    "        self._load_datas()\n",
    "        print(\"[Load] %d's poses SLAM data loaded\" % len(self.poses))\n",
    "    \n",
    "    def _load_gt_pairs(self):\n",
    "        file_path = os.path.join(self.dataset_dir, 'groundtruths128', '%02d'%self.seq, 'groundtruths.txt')\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines_list = f.readlines()\n",
    "            for i, line_str in enumerate(lines_list):\n",
    "                if i == 0:\n",
    "                    continue # skip the header line\n",
    "                line_splitted = line_str.split()\n",
    "                anc_idx = int(float(line_splitted[0]))\n",
    "                pos_idx = int(float(line_splitted[1]))\n",
    "\n",
    "                data = {'seq': self.seq, 'anc_idx': anc_idx, 'pos_idx': pos_idx}\n",
    "                self.gt_pairs.append(data)\n",
    "\n",
    "    def _load_datas(self):\n",
    "        # poses\n",
    "        pose_path = os.path.join(self.dataset_dir, 'poses', '%02d.txt'%self.seq)\n",
    "        with open(pose_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T_w_cam0 = np.fromstring(line, dtype=float, sep=' ')\n",
    "                T_w_cam0 = T_w_cam0.reshape(3, 4)\n",
    "                T_w_cam0 = np.vstack((T_w_cam0, [0, 0, 0, 1]))\n",
    "                self.poses.append(T_w_cam0)\n",
    "\n",
    "        # keypoints, scores and descriptors\n",
    "        keypoint_folder = os.path.join(self.dataset_dir, 'keypoints', '%02d'%self.seq)\n",
    "        keypoint_folder = os.listdir(keypoint_folder)   \n",
    "        keypoint_folder.sort(key=lambda x:int(x[:-4]))\n",
    "        for idx in range(len(keypoint_folder)):\n",
    "            file = os.path.join(self.dataset_dir, 'keypoints', '%02d'%self.seq, keypoint_folder[idx])\n",
    "            if os.path.isfile(file):\n",
    "                pc = np.reshape(np.fromfile(file, dtype=np.float64), (-1, 139))\n",
    "                self.keypoints.append(pc[:, :3])\n",
    "                self.scores.append(pc[:, 3])\n",
    "                self.descriptors.append(pc[:, 4:])\n",
    "            else:\n",
    "                self.keypoints.append([0.0, 0.0, 0.0])\n",
    "                self.scores.append([0])\n",
    "                self.descriptors.append([0.0]*135)\n",
    "\n",
    "        # dense scans\n",
    "        dense_folder = os.path.join(self.dataset_dir, 'dense_scan', '%02d'%self.seq)\n",
    "        dense_folder = os.listdir(dense_folder)\n",
    "        dense_folder.sort(key=lambda x:int(x[:-4]))\n",
    "        for idx in range(len(dense_folder)):\n",
    "            file = os.path.join(self.dataset_dir, 'dense_scan', '%02d'%self.seq, dense_folder[idx])\n",
    "            if os.path.isfile(file):\n",
    "                self.dense_scans.append(np.reshape(np.fromfile(file, dtype=np.float64), (-1, 3)))\n",
    "            else:\n",
    "                self.dense_scans.append(np.array([0, 0, 0]))\n",
    "\n",
    "    def get_gt_pairs(self, idx):\n",
    "        index_in_seq0 = self.gt_pairs[idx]['anc_idx']\n",
    "        index_in_seq1 = self.gt_pairs[idx]['pos_idx']\n",
    "\n",
    "        pose0 = torch.tensor(self.poses[index_in_seq0], dtype=torch.double)\n",
    "        pose1 = torch.tensor(self.poses[index_in_seq1], dtype=torch.double)\n",
    "        T_gt = torch.einsum('ab,de->ae', torch.inverse(pose0), pose1)\n",
    "\n",
    "        pc0 = self.dense_scans[index_in_seq0]\n",
    "        pc1 = self.dense_scans[index_in_seq1]\n",
    "\n",
    "        kp0_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in self.keypoints[index_in_seq0]]) \n",
    "        kp1_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in self.keypoints[index_in_seq1]])\n",
    "        kp0_tensor = torch.tensor(kp0_np, dtype=torch.double)\n",
    "        kp1_tensor = torch.tensor(kp1_np, dtype=torch.double)\n",
    "\n",
    "        kp0_local_tensor = torch.einsum('ij,nj->ni', torch.inverse(pose0), kp0_tensor).double()\n",
    "        kp1_local_tensor = torch.einsum('ij,nj->ni', torch.inverse(pose1), kp1_tensor).double()\n",
    "\n",
    "        desc0 = self.descriptors[index_in_seq0]\n",
    "        desc1 = self.descriptors[index_in_seq1]\n",
    "\n",
    "        kp0_num = len(kp0_tensor)\n",
    "        kp1_num = len(kp1_tensor)\n",
    "\n",
    "        norm0, norm1 = np.linalg.norm(desc0, axis=1), np.linalg.norm(desc1, axis=1)\n",
    "        norm0, norm1 = norm0.reshape(kp0_num, 1), norm1.reshape(kp1_num, 1)\n",
    "        epsilon = 1e-8  # small constant to prevent division by zero\n",
    "        norm0, norm1 = norm0 + epsilon, norm1 + epsilon\n",
    "        desc0, desc1 = np.where(norm0 != 0, np.multiply(desc0, 1/norm0), 0), np.where(norm1 != 0, np.multiply(desc1, 1/norm1), 0)\n",
    "\n",
    "        desc0_tensor, desc1_tensor = torch.tensor(desc0, dtype=torch.double), torch.tensor(desc1, dtype=torch.double)\n",
    "        scores0_tensor, scores1_tensor = torch.tensor(self.scores[index_in_seq0], dtype=torch.double), torch.tensor(self.scores[index_in_seq1], dtype=torch.double)\n",
    "\n",
    "        dists = cdist(kp0_tensor, kp1_tensor)\n",
    "        '''Find ground true keypoint matching'''\n",
    "        min1 = np.argmin(dists, axis=0)\n",
    "        min2 = np.argmin(dists, axis=1)\n",
    "        min1v = np.min(dists, axis=1)\n",
    "        min1f = min2[min1v < 0.5]\n",
    "\n",
    "        '''For calculating repeatibility'''\n",
    "        rep = len(min1f)\n",
    "\n",
    "        match1, match2 = -1 * np.ones((len(kp0_tensor)), dtype=np.int16), -1 * np.ones((len(kp1_tensor)), dtype=np.int16)\n",
    "        match1[min1v < 0.5] = min1f\n",
    "        min2v = np.min(dists, axis=0)\n",
    "        min2f = min1[min2v < 0.5]\n",
    "        match2[min2v < 0.5] = min2f\n",
    "            \n",
    "        # print(kp0_tensor.shape)\n",
    "        # print(kp0_tensor[:,:3].shape)\n",
    "\n",
    "        return{\n",
    "            # 'skip': False,\n",
    "            'keypoints0': kp0_local_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints1': kp1_local_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints_global_0': kp0_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints_global_1': kp1_tensor[:,:3].unsqueeze(0),\n",
    "            'descriptors0': desc0_tensor.unsqueeze(0),\n",
    "            'descriptors1': desc1_tensor.unsqueeze(0),\n",
    "            'scores0': scores0_tensor.unsqueeze(0),\n",
    "            'scores1': scores1_tensor.unsqueeze(0),\n",
    "            'gt_matches0': match1,\n",
    "            'gt_matches1': match2,\n",
    "            'sequence': self.seq,\n",
    "            'idx0': index_in_seq0,\n",
    "            'idx1': index_in_seq1,\n",
    "            'pose1': pose0,\n",
    "            'pose2': pose1,\n",
    "            # 'T_cam0_velo': T_cam0_velo,\n",
    "            'T_gt': T_gt,\n",
    "            'cloud0': pc0,\n",
    "            'cloud1': pc1,\n",
    "            # 'all_matches': list(all_matches),\n",
    "            # 'file_name': file_name\n",
    "            'rep': rep\n",
    "        }\n",
    "    \n",
    "    def process_global_keypoints(self):\n",
    "        pass\n",
    "    \n",
    "    def matching_test_1to2(self, idx, range_of_global_graph = 50, range_of_local_graph = 10):\n",
    "        index_in_seq0 = self.gt_pairs[idx]['anc_idx']\n",
    "        index_in_seq1 = self.gt_pairs[idx]['pos_idx']\n",
    "        while index_in_seq0 <= range_of_global_graph:\n",
    "            idx+=1\n",
    "            index_in_seq0 = self.gt_pairs[idx]['anc_idx']\n",
    "            index_in_seq1 = self.gt_pairs[idx]['pos_idx']\n",
    "            \n",
    "        pose0 = torch.tensor(self.poses[index_in_seq0], dtype=torch.double)\n",
    "        pose1 = torch.tensor(self.poses[index_in_seq1], dtype=torch.double)\n",
    "        T_gt = torch.einsum('ab,de->ae', torch.inverse(pose0), pose1)\n",
    "\n",
    "        pc0_o3d = o3d.geometry.PointCloud()\n",
    "        for i in range(index_in_seq0-range_of_global_graph, index_in_seq0):\n",
    "            pc0_o3d.points.extend(self.dense_scans[i])\n",
    "        pc0_o3d.voxel_down_sample(voxel_size=0.2)\n",
    "        pc0 = np.array(pc0_o3d.points)\n",
    "        pc1_o3d = o3d.geometry.PointCloud()\n",
    "        for i in range(index_in_seq1, index_in_seq1+range_of_local_graph):\n",
    "            pc1_o3d.points.extend(self.dense_scans[i])\n",
    "        pc1_o3d.voxel_down_sample(voxel_size=0.2)\n",
    "        pc1 = np.array(pc1_o3d.points)\n",
    "\n",
    "        kp0_list = []\n",
    "        kp0_for_desc = []\n",
    "        desc0_list = []\n",
    "        for i in range(index_in_seq0-range_of_global_graph, index_in_seq0):\n",
    "            kp0_list.append(self.keypoints[i])\n",
    "            for kp_idx in range(self.keypoints[i].shape[0]):\n",
    "                kp0_for_desc.append(self.keypoints[i][kp_idx])\n",
    "                desc0_list.append(self.descriptors[i][kp_idx])\n",
    "        o3d_kp0 = o3d.geometry.PointCloud()\n",
    "        for i in range(len(kp0_list)):\n",
    "            o3d_kp0.points.extend(kp0_list[i])\n",
    "\n",
    "        labels = np.array(o3d_kp0.cluster_dbscan(eps=0.3, min_points=4, print_progress=False))\n",
    "        if len(labels) > 0:\n",
    "            max_label = labels.max()  # max_label represents the number of clusters\n",
    "            merged_keypoints_chach = [[] for _ in range(max_label+1)]\n",
    "            \n",
    "            # Group keypoints based on their labels (clusters)\n",
    "            for idx, label in enumerate(labels):\n",
    "                if label >= 0:\n",
    "                    merged_keypoints_chach[label].append(np.array(o3d_kp0.points[idx]))\n",
    "            keypoint_chach = []\n",
    "            # Calculate the mean point for each cluster and add it to keypoint_chach\n",
    "            for pi in merged_keypoints_chach:\n",
    "                p = np.mean(pi, axis=0)\n",
    "                keypoint_chach.append(p)\n",
    "        kp0 = np.array(keypoint_chach)\n",
    "\n",
    "        kp1_list = []\n",
    "        kp1_for_desc = []\n",
    "        desc1_list = []\n",
    "        for i in range(index_in_seq1, index_in_seq1 + range_of_local_graph):\n",
    "            kp1_list.append(self.keypoints[i])\n",
    "            for kp_idx in range(self.keypoints[i].shape[0]):\n",
    "                kp1_for_desc.append(self.keypoints[i][kp_idx])\n",
    "                desc1_list.append(self.descriptors[i][kp_idx])\n",
    "        o3d_kp1 = o3d.geometry.PointCloud()\n",
    "        for i in range(len(kp1_list)):\n",
    "            o3d_kp1.points.extend(kp1_list[i])\n",
    "\n",
    "        labels = np.array(o3d_kp1.cluster_dbscan(eps=0.3, min_points=4, print_progress=False))\n",
    "        if len(labels) > 0:\n",
    "            max_label = labels.max()  # max_label represents the number of clusters\n",
    "            merged_keypoints_chach = [[] for _ in range(max_label+1)]\n",
    "            \n",
    "            # Group keypoints based on their labels (clusters)\n",
    "            for idx, label in enumerate(labels):\n",
    "                if label >= 0:\n",
    "                    merged_keypoints_chach[label].append(np.array(o3d_kp1.points[idx]))\n",
    "            keypoint_chach = []\n",
    "            # Calculate the mean point for each cluster and add it to keypoint_chach\n",
    "            for pi in merged_keypoints_chach:\n",
    "                p = np.mean(pi, axis=0)\n",
    "                keypoint_chach.append(p)\n",
    "        kp1 = np.array(keypoint_chach)\n",
    "\n",
    "        kp0_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in kp0])\n",
    "        kp1_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in kp1])\n",
    "        kp0_tensor = torch.tensor(kp0_np, dtype=torch.double)\n",
    "        kp1_tensor = torch.tensor(kp1_np, dtype=torch.double)\n",
    "        kp0_num = len(kp0_tensor)\n",
    "        kp1_num = len(kp1_tensor)\n",
    "\n",
    "        desc0 = []\n",
    "        scores0 = []\n",
    "        desc1 = []\n",
    "        scores1 = []\n",
    "        for i in range(kp0.shape[0]):\n",
    "            min_dist = 100000\n",
    "            min_idx = 0\n",
    "            for j in range(len(kp0_for_desc)):\n",
    "                dist = np.linalg.norm(kp0[i] - kp0_for_desc[j])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_idx = j\n",
    "            kp0[i] = kp0_for_desc[min_idx]\n",
    "            desc0.append(desc0_list[min_idx])\n",
    "            scores0.append(1)\n",
    "        desc0 = np.array(desc0)\n",
    "        scores0 = np.array(scores0)\n",
    "\n",
    "        for i in range(kp1.shape[0]):\n",
    "            min_dist = 100000\n",
    "            min_idx = 0\n",
    "            for j in range(len(kp1_for_desc)):\n",
    "                dist = np.linalg.norm(kp1[i] - kp1_for_desc[j])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_idx = j\n",
    "            kp1[i] = kp1_for_desc[min_idx]\n",
    "            desc1.append(desc1_list[min_idx])\n",
    "            scores1.append(1)\n",
    "        desc1 = np.array(desc1)\n",
    "        scores1 = np.array(scores1)\n",
    "\n",
    "        kp0_local_tensor = torch.einsum('ij,nj->ni', torch.inverse(pose0), kp0_tensor).double()\n",
    "        kp1_local_tensor = torch.einsum('ij,nj->ni', torch.inverse(pose1), kp1_tensor).double()\n",
    "\n",
    "        norm0, norm1 = np.linalg.norm(desc0, axis=1), np.linalg.norm(desc1, axis=1)\n",
    "        norm0, norm1 = norm0.reshape(kp0_num, 1), norm1.reshape(kp1_num, 1)\n",
    "        epsilon = 1e-8  # small constant to prevent division by zero\n",
    "        norm0, norm1 = norm0 + epsilon, norm1 + epsilon\n",
    "        desc0, desc1 = np.where(norm0 != 0, np.multiply(desc0, 1/norm0), 0), np.where(norm1 != 0, np.multiply(desc1, 1/norm1), 0)\n",
    "\n",
    "        desc0_tensor, desc1_tensor = torch.tensor(desc0, dtype=torch.double), torch.tensor(desc1, dtype=torch.double)\n",
    "        scores0_tensor, scores1_tensor = torch.tensor(scores0, dtype=torch.double), torch.tensor(scores1, dtype=torch.double)\n",
    "\n",
    "        dists = cdist(kp0_tensor, kp1_tensor)\n",
    "        '''Find ground true keypoint matching'''\n",
    "        min1 = np.argmin(dists, axis=0)\n",
    "        min2 = np.argmin(dists, axis=1)\n",
    "        min1v = np.min(dists, axis=1)\n",
    "        min1f = min2[min1v < 0.5]\n",
    "\n",
    "        '''For calculating repeatibility'''\n",
    "        rep = len(min1f)\n",
    "\n",
    "        match1, match2 = -1 * np.ones((len(kp0_tensor)), dtype=np.int16), -1 * np.ones((len(kp1_tensor)), dtype=np.int16)\n",
    "        match1[min1v < 0.5] = min1f\n",
    "        min2v = np.min(dists, axis=0)\n",
    "        min2f = min1[min2v < 0.5]\n",
    "        match2[min2v < 0.5] = min2f\n",
    "            \n",
    "        # print(kp0_tensor.shape)\n",
    "        # print(kp0_tensor[:,:3].shape)\n",
    "\n",
    "        return{\n",
    "            # 'skip': False,\n",
    "            'keypoints0': kp0_local_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints1': kp1_local_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints_global_0': kp0_tensor[:,:3].unsqueeze(0),\n",
    "            'keypoints_global_1': kp1_tensor[:,:3].unsqueeze(0),\n",
    "            'descriptors0': desc0_tensor.unsqueeze(0),\n",
    "            'descriptors1': desc1_tensor.unsqueeze(0),\n",
    "            'scores0': scores0_tensor.unsqueeze(0),\n",
    "            'scores1': scores1_tensor.unsqueeze(0),\n",
    "            'gt_matches0': match1,\n",
    "            'gt_matches1': match2,\n",
    "            'sequence': self.seq,\n",
    "            'idx0': index_in_seq0,\n",
    "            'idx1': index_in_seq1,\n",
    "            'pose1': pose0,\n",
    "            'pose2': pose1,\n",
    "            # 'T_cam0_velo': T_cam0_velo,\n",
    "            'T_gt': T_gt,\n",
    "            'cloud0': pc0,\n",
    "            'cloud1': pc1,\n",
    "            # 'all_matches': list(all_matches),\n",
    "            # 'file_name': file_name\n",
    "            'rep': rep\n",
    "        }\n",
    "    \n",
    "    def global_matching(self, idx):\n",
    "        pass\n",
    "                                     \n",
    "    def __len__(self):\n",
    "        return len(self.poses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emplimentation 테스트 시나리오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load] 1530's poses SLAM data loaded\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.kenc.encoder.0.weight: copying a param with shape torch.Size([16, 3, 1]) from checkpoint, the shape in current model is torch.Size([32, 4, 1]).\n\tsize mismatch for module.kenc.encoder.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.3.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 1]).\n\tsize mismatch for module.kenc.encoder.3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.6.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).\n\tsize mismatch for module.kenc.encoder.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.9.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.kenc.encoder.9.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.0.weight: copying a param with shape torch.Size([128, 135, 1]) from checkpoint, the shape in current model is torch.Size([64, 135, 1]).\n\tsize mismatch for module.denc.encoder.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).\n\tsize mismatch for module.denc.encoder.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.6.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.denc.encoder.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.0.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.0.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.1.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.1.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.2.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.2.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.3.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.3.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.4.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.4.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.5.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.5.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.6.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.6.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.7.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.7.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.8.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.8.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.9.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.9.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.10.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.10.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.11.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.11.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.12.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.12.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.13.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.13.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.14.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.14.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.15.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.15.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.16.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.16.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.17.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.17.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.final_proj.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.final_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     25\u001b[0m net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(net)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m net\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# torch.cuda.set_device(opt.local_rank)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mdgat/lib/python3.10/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.kenc.encoder.0.weight: copying a param with shape torch.Size([16, 3, 1]) from checkpoint, the shape in current model is torch.Size([32, 4, 1]).\n\tsize mismatch for module.kenc.encoder.0.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.1.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module.kenc.encoder.3.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 1]).\n\tsize mismatch for module.kenc.encoder.3.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.4.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.kenc.encoder.6.weight: copying a param with shape torch.Size([64, 32, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).\n\tsize mismatch for module.kenc.encoder.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.7.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.kenc.encoder.9.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.kenc.encoder.9.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.0.weight: copying a param with shape torch.Size([128, 135, 1]) from checkpoint, the shape in current model is torch.Size([64, 135, 1]).\n\tsize mismatch for module.denc.encoder.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for module.denc.encoder.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1]).\n\tsize mismatch for module.denc.encoder.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.4.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.denc.encoder.6.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.denc.encoder.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.0.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.0.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.0.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.0.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.0.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.1.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.1.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.1.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.1.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.1.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.2.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.2.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.2.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.2.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.2.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.3.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.3.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.3.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.3.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.3.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.4.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.4.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.4.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.4.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.4.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.5.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.5.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.5.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.5.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.5.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.6.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.6.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.6.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.6.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.6.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.7.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.7.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.7.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.7.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.7.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.8.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.8.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.8.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.8.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.8.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.9.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.9.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.9.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.9.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.9.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.10.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.10.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.10.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.10.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.10.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.11.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.11.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.11.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.11.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.11.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.12.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.12.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.12.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.12.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.12.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.13.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.13.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.13.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.13.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.13.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.14.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.14.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.14.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.14.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.14.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.15.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.15.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.15.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.15.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.15.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.16.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.16.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.16.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.16.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.16.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.merge.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.merge.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.0.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.1.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.2.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.gnn.layers.17.attn.proj.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.gnn.layers.17.mlp.0.weight: copying a param with shape torch.Size([128, 128, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1]).\n\tsize mismatch for module.gnn.layers.17.mlp.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.gnn.layers.17.mlp.3.weight: copying a param with shape torch.Size([64, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1]).\n\tsize mismatch for module.gnn.layers.17.mlp.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module.final_proj.weight: copying a param with shape torch.Size([64, 64, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1]).\n\tsize mismatch for module.final_proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "# 1. 데이터 로드\n",
    "dataset = Kitti_Rops_dataset_loader(opt)\n",
    "\n",
    "# 2. 모델 로드\n",
    "from models.mdgat_Rops import MDGAT\n",
    "path_checkpoint = opt.resume_model  \n",
    "checkpoint = torch.load(path_checkpoint, map_location={'cuda:2':'cuda:0'})  \n",
    "lr = checkpoint['lr_schedule']\n",
    "config = {\n",
    "    'net': {\n",
    "        'sinkhorn_iterations': opt.sinkhorn_iterations,\n",
    "        'match_threshold': opt.match_threshold,\n",
    "        'lr': opt.learning_rate,\n",
    "        'loss_method': opt.loss_method,\n",
    "        'k': opt.k,\n",
    "        'descriptor': opt.descriptor,\n",
    "        'mutual_check': opt.mutual_check,\n",
    "        'triplet_loss_gamma': opt.triplet_loss_gamma,\n",
    "        'train_step':opt.train_step,\n",
    "        'L':opt.l\n",
    "    }\n",
    "}\n",
    "net = MDGAT(config.get('net', {}))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=config.get('net', {}).get('lr'))\n",
    "net = torch.nn.DataParallel(net)\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net.double().eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # torch.cuda.set_device(opt.local_rank)\n",
    "    device=torch.device('cuda:{}'.format(opt.local_rank))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"### CUDA not available ###\")\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매트릭 코드 짜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_loss = []; precision_array = []; accuracy_array = []; recall_array = []\n",
    "trans_error_array = []; rot_error_array = []; relative_trans_error_array = []; relative_rot_error_array = []\n",
    "repeatibilty_array = []; valid_num_array = []; all_num_array = []; inlier_array = [] \n",
    "kpnum_array = []; fp_rate_array = []; tp_rate_array = []; tp_rate2_array = []; inlier_ratio_array= [];tm_a=[];fm_a=[]\n",
    "fail = 0\n",
    "baned_data = 0\n",
    "for pair in range(len(dataset.gt_pairs)):\n",
    "# for pair in [0]:\n",
    "    pred = dataset.get_gt_pairs(pair)\n",
    "    for p in pred:\n",
    "        if type(pred[p]) == torch.Tensor:\n",
    "            pred[p] = pred[p].to(device)\n",
    "    data = net.module.infer_mdgat(pred)\n",
    "    pred = {**pred, **data}\n",
    "\n",
    "    kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "    kpts_g_0, kpts_g_1 = pred['keypoints_global_0'][0].cpu().numpy(), pred['keypoints_global_1'][0].cpu().numpy()\n",
    "    matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "    gt_match0, gt_match1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "    valid = matches0 > -1\n",
    "    mkpts0 = kpts0[valid]\n",
    "    mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "    mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "    mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "    mutual1 = matches0[mutual0]\n",
    "    x = np.ones(len(matches1)) == 1\n",
    "    x[mutual1] = False\n",
    "    valid1 = matches1 > -1\n",
    "\n",
    "    mconf = conf[valid]\n",
    "\n",
    "    ## ground truth ##\n",
    "    matches_gt, matches_gt1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "    matches_gt[matches_gt == len(matches_gt1)] = -1\n",
    "    matches_gt1[matches_gt1 == len(matches_gt)] = -1\n",
    "    valid_gt = matches_gt > -1\n",
    "\n",
    "    valid_num = np.sum(valid_gt)\n",
    "    all_num = len(valid_gt)\n",
    "    repeatibilty = valid_num/all_num\n",
    "    repeatibilty_array.append(repeatibilty)\n",
    "\n",
    "    mkpts0_gt = kpts0[valid_gt]\n",
    "    mkpts1_gt = kpts1[matches_gt[valid_gt]]\n",
    "    mutual0 = np.arange(len(matches_gt))[valid_gt] == matches_gt1[matches_gt[valid_gt]]\n",
    "    # mutual0_inv = 1-mutual0\n",
    "    mutual0 = np.arange(len(matches_gt))[valid_gt][mutual0]\n",
    "    mutual1 = matches_gt[mutual0]\n",
    "    x = np.ones(len(matches_gt1)) == 1\n",
    "    x[mutual1] = False               \n",
    "    valid_gt1 = matches_gt1 > -1\n",
    "\n",
    "    mscores_gt = pred['scores0'][0].cpu().numpy()[valid_gt]\n",
    "    gt_idx = np.arange(len(kpts0))[valid_gt]\n",
    "\n",
    "    if len(mkpts0) < 4:\n",
    "        fail+=1\n",
    "        print('registration fail')\n",
    "\n",
    "    ''' calculate false positive ,true positive ,true nagetive, precision, accuracy, recall '''\n",
    "    true_positive = [(matches0[i] == matches_gt[i]) and (valid[i]) for i in range(len(kpts0))]\n",
    "    true_negativate = [(matches0[i] == matches_gt[i]) and not (valid[i]) for i in range(len(kpts0))]\n",
    "    false_positive = [valid[i] and (matches_gt[i]==-1) for i in range(len(kpts0))]\n",
    "    ckpts0 = kpts0[true_positive]\n",
    "    ckpts1 = [matches0[true_positive]]\n",
    "    precision = np.sum(true_positive) / np.sum(valid) if np.sum(valid) > 0 else 0\n",
    "    recall = np.sum(true_positive) / np.sum(valid_gt) if np.sum(valid) > 0 else 0\n",
    "    tm = np.sum(true_positive) \n",
    "    fm = np.sum(false_positive) \n",
    "    matching_score = np.sum(true_positive) / len(kpts0) if len(kpts0) > 0 else 0\n",
    "    accuracy = (np.sum(true_positive) + np.sum(true_negativate))/len(matches_gt)\n",
    "    fp_rate = np.sum(false_positive)/np.sum(matches_gt==-1)\n",
    "    tp_rate = np.sum([valid[i] and (matches_gt[i]>-1) for i in range(len(kpts0))])/np.sum(matches_gt > -1)\n",
    "    tp_rate2 = np.sum(true_positive)/np.sum(matches_gt > -1)\n",
    "    T=[]\n",
    "    print('idx{}, precision {:.3f}, accuracy {:.3f}, recall {:.3f}, true match {:.3f}, false match {:.3f}, fp_rate {:.3f}, tp_rate {:.3f}'.format(\n",
    "        pair, precision, accuracy, recall,tm,fm, fp_rate, tp_rate))\n",
    "    precision_array.append(precision)\n",
    "    accuracy_array.append(accuracy)\n",
    "    recall_array.append(recall)\n",
    "    fp_rate_array.append(fp_rate)\n",
    "    tp_rate_array.append(tp_rate)\n",
    "    tp_rate2_array.append(tp_rate2)\n",
    "    tm_a.append(tm)\n",
    "    fm_a.append(fm)\n",
    "precision_mean = np.mean(precision_array)\n",
    "accuracy_mean = np.mean(accuracy_array)\n",
    "recall_mean = np.mean(recall_array)\n",
    "repeatibilty_array_mean = np.mean(repeatibilty_array)\n",
    "fp_rate_mean = np.mean(fp_rate_array)\n",
    "tp_rate_mean = np.mean(tp_rate_array)\n",
    "tp_rate_mean2 = np.mean(tp_rate2_array)\n",
    "tm = np.mean(tm_a)\n",
    "fm = np.mean(fm_a)\n",
    "print('average repeatibility: {:.3f}, fail {:.6f}, precision_mean {:.3f}, accuracy_mean {:.3f}, recall_mean {:.3f}, true match {:.3f}, false match {:.3f}, fp_rate_mean {:.3f}, tp_rate_mean {:.3f}, tp_rate_mean2 {:.3f}, trans_error_mean {:.3f}, rot_error_mean {:.3f} '.format(\n",
    "    repeatibilty_array_mean, fail/pair, precision_mean, accuracy_mean, recall_mean,tm,fm, fp_rate_mean, tp_rate_mean, tp_rate_mean2, trans_error_mean, rot_error_mean ))\n",
    "# print('valid num {}, all_num {}'.format(valid_num_mean, all_num_mean))\n",
    "print('baned_data {}'.format(baned_data/pair))\n",
    "\n",
    "  #average repeatibility: 0.593, fail 0.002518, precision_mean 0.947, accuracy_mean 0.944, recall_mean 0.915, true match 111.825, false match 2.146, fp_rate_mean 0.027, tp_rate_mean 0.939, tp_rate_mean2 0.915, trans_error_mean nan, rot_error_mean nan \n",
    "# baned_data 0.0\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매칭 비주얼로 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in range(0, len(dataset.gt_pairs), 10):\n",
    "    pred = dataset.get_gt_pairs(pair)\n",
    "    for p in pred:\n",
    "        if type(pred[p]) == torch.Tensor:\n",
    "            pred[p] = pred[p].to(device)\n",
    "    data = net.module.infer_mdgat(pred)\n",
    "    pred = {**pred, **data}\n",
    "\n",
    "    kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "    kpts_g_0, kpts_g_1 = pred['keypoints_global_0'][0].cpu().numpy(), pred['keypoints_global_1'][0].cpu().numpy()\n",
    "    matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "    gt_match0, gt_match1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "    valid = matches0 > -1\n",
    "    mkpts0 = kpts0[valid]\n",
    "    mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "    mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "    mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "    mutual1 = matches0[mutual0]\n",
    "    x = np.ones(len(matches1)) == 1\n",
    "    x[mutual1] = False\n",
    "    valid1 = matches1 > -1\n",
    "\n",
    "    mconf = conf[valid]    \n",
    "\n",
    "    pcd_kp0 = o3d.geometry.PointCloud()\n",
    "    pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "    pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "    pcd_kp1 = o3d.geometry.PointCloud()\n",
    "    pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "    pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "    points = np.concatenate((np.array(pcd_kp0.points),np.array(pcd_kp1.points)), axis=0) # >> pcd_kp0에 pcd_kp1를 이어 붙힘\n",
    "    lines = []\n",
    "    colors = []\n",
    "    for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "        lines.append([match, mutual1[idx] + len(kpts0)])\n",
    "        # lines.append([match, mutual1[idx] + len(kpts_g_0)])\n",
    "        point1 = kpts_g_0[match]\n",
    "        point2 = kpts_g_1[mutual1[idx]]\n",
    "        if np.linalg.norm(point1 - point2) < 1.0:\n",
    "            colors.append([0, 1, 0])\n",
    "        else: \n",
    "            colors.append([1, 0, 0])\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector((points)),\n",
    "        lines=o3d.utility.Vector2iVector(lines),\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    # o3d.visualization.draw_geometries([pcd0,pcd1,line_set])\n",
    "\n",
    "    # o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])\n",
    "    o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제상황처럼 테스트 해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Kitti_Rops_dataset_loader(opt)\n",
    "\n",
    "pred = dataset.matching_test_1to2(500, 50, 50)\n",
    "\n",
    "kp0 = pred['keypoints_global_0'][0].cpu().numpy()\n",
    "kp1 = pred['keypoints_global_1'][0].cpu().numpy()\n",
    "pc0 = pred['cloud0']\n",
    "pc1 = pred['cloud1']\n",
    "\n",
    "kp0_o3d = o3d.geometry.PointCloud()\n",
    "kp0_o3d.points = o3d.utility.Vector3dVector(kp0)\n",
    "kp0_o3d.paint_uniform_color([0, 1, 0])\n",
    "kp1_o3d = o3d.geometry.PointCloud()\n",
    "kp1_o3d.points = o3d.utility.Vector3dVector(kp1)\n",
    "kp1_o3d.paint_uniform_color([1, 0, 0])\n",
    "pc0_o3d = o3d.geometry.PointCloud()\n",
    "pc0_o3d.points = o3d.utility.Vector3dVector(pc0)\n",
    "pc0_o3d.paint_uniform_color([0.7, 1, 0.7])\n",
    "pc1_o3d = o3d.geometry.PointCloud()\n",
    "pc1_o3d.points = o3d.utility.Vector3dVector(pc1)\n",
    "pc1_o3d.paint_uniform_color([1, 0.7, 0.7])\n",
    "\n",
    "# o3d.visualization.draw_geometries([kp0_o3d, kp1_o3d, pc0_o3d, pc1_o3d])\n",
    "o3d.visualization.draw_geometries([kp0_o3d, kp1_o3d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair in range(160, len(dataset.gt_pairs), 10):\n",
    "pair = 140\n",
    "for range0 in [10, 20, 30, 40, 50, 60]:\n",
    "    for range1 in [10, 20, 30, 40, 50, 60]:\n",
    "        pred = dataset.matching_test_1to2(pair, range0, range1)\n",
    "        for p in pred:\n",
    "            if type(pred[p]) == torch.Tensor:\n",
    "                pred[p] = pred[p].to(device)\n",
    "        print(pred['keypoints0'].shape, pred['keypoints1'].shape, pred['descriptors0'].shape, pred['descriptors1'].shape, pred['scores0'].shape, pred['scores1'].shape)\n",
    "\n",
    "        data = net.module.infer_mdgat(pred)\n",
    "        pred = {**pred, **data}\n",
    "\n",
    "        kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "        kpts_g_0, kpts_g_1 = pred['keypoints_global_0'][0].cpu().numpy(), pred['keypoints_global_1'][0].cpu().numpy()\n",
    "        matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "        gt_match0, gt_match1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "        valid = matches0 > -1\n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "        mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "        mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "        mutual1 = matches0[mutual0]\n",
    "        x = np.ones(len(matches1)) == 1\n",
    "        x[mutual1] = False\n",
    "        valid1 = matches1 > -1\n",
    "\n",
    "        mconf = conf[valid]    \n",
    "\n",
    "        pcd_kp0 = o3d.geometry.PointCloud()\n",
    "        pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "        pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "        pcd_kp1 = o3d.geometry.PointCloud()\n",
    "        pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "        pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "        points = np.concatenate((np.array(pcd_kp0.points),np.array(pcd_kp1.points)), axis=0) # >> pcd_kp0에 pcd_kp1를 이어 붙힘\n",
    "        lines = []\n",
    "        colors = []\n",
    "        for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "            lines.append([match, mutual1[idx] + len(kpts0)])\n",
    "            # lines.append([match, mutual1[idx] + len(kpts_g_0)])\n",
    "            point1 = kpts_g_0[match]\n",
    "            point2 = kpts_g_1[mutual1[idx]]\n",
    "            if np.linalg.norm(point1 - point2) < 1.0:\n",
    "                colors.append([0, 1, 0])\n",
    "            else: \n",
    "                colors.append([1, 0, 0])\n",
    "        line_set = o3d.geometry.LineSet(\n",
    "            points=o3d.utility.Vector3dVector((points)),\n",
    "            lines=o3d.utility.Vector2iVector(lines),\n",
    "        )\n",
    "        line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "        # o3d.visualization.draw_geometries([pcd0,pcd1,line_set])\n",
    "\n",
    "        # o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])\n",
    "        o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair in range(160, len(dataset.gt_pairs), 10):\n",
    "pair = 140\n",
    "for range0 in [10, 20, 30, 40, 50, 60]:\n",
    "    for range1 in [10, 20, 30, 40, 50, 60]:\n",
    "        pred = dataset.matching_test_1to2(pair, range0, range1)\n",
    "        for p in pred:\n",
    "            if type(pred[p]) == torch.Tensor:\n",
    "                pred[p] = pred[p].to(device)\n",
    "        print(pred['keypoints0'].shape, pred['keypoints1'].shape, pred['descriptors0'].shape, pred['descriptors1'].shape, pred['scores0'].shape, pred['scores1'].shape)\n",
    "\n",
    "        data = net.module.infer_mdgat(pred)\n",
    "        pred = {**pred, **data}\n",
    "\n",
    "        kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "        kpts_g_0, kpts_g_1 = pred['keypoints_global_0'][0].cpu().numpy(), pred['keypoints_global_1'][0].cpu().numpy()\n",
    "        matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "        gt_match0, gt_match1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "        valid = matches0 > -1\n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "        mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "        mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "        mutual1 = matches0[mutual0]\n",
    "        x = np.ones(len(matches1)) == 1\n",
    "        x[mutual1] = False\n",
    "        valid1 = matches1 > -1\n",
    "\n",
    "        mconf = conf[valid]\n",
    "\n",
    "        gt_match_num = 0\n",
    "        for i in gt_match0:\n",
    "            if i > -1:\n",
    "                gt_match_num+=1\n",
    "                \n",
    "        matched_num = 0\n",
    "        miss_matched_num = 0\n",
    "        for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "            point1 = kpts_g_0[match]\n",
    "            point2 = kpts_g_1[mutual1[idx]]\n",
    "            if np.linalg.norm(point1 - point2) < 0.5:\n",
    "                matched_num+=1\n",
    "            else: \n",
    "                miss_matched_num+=1\n",
    "\n",
    "        print('range0 {}, range1 {}, gt_match_num {}, matched_num {}, miss_matched_num {}'.format(range0, range1, gt_match_num, matched_num, miss_matched_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "kpts_g_0, kpts_g_1 = pred['keypoints_global_0'][0].cpu().numpy(), pred['keypoints_global_1'][0].cpu().numpy()\n",
    "matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "gt_match0, gt_match1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "valid = matches0 > -1\n",
    "mkpts0 = kpts0[valid]\n",
    "mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "mutual1 = matches0[mutual0]\n",
    "x = np.ones(len(matches1)) == 1\n",
    "x[mutual1] = False\n",
    "valid1 = matches1 > -1\n",
    "\n",
    "mconf = conf[valid]\n",
    "\n",
    "# matches_gt, matches_gt1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "# matches_gt[matches_gt == len(matches_gt1)] = -1\n",
    "# matches_gt1[matches_gt1 == len(matches_gt)] = -1\n",
    "# valid_gt = matches_gt > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mutual0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_kp_g_0 = o3d.geometry.PointCloud()\n",
    "pcd_kp_g_0.points = o3d.utility.Vector3dVector(kpts_g_0)\n",
    "pcd_kp_g_0.paint_uniform_color([0, 0, 1])\n",
    "pcd_kp_g_1 = o3d.geometry.PointCloud()\n",
    "pcd_kp_g_1.points = o3d.utility.Vector3dVector(kpts_g_1)\n",
    "pcd_kp_g_1.paint_uniform_color([0, 1, 0])\n",
    "o3d.visualization.draw_geometries([pcd_kp_g_0, pcd_kp_g_1, line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "pcd_kp0 = o3d.geometry.PointCloud()\n",
    "pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "pcd_kp1 = o3d.geometry.PointCloud()\n",
    "pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "pcd_kp_g_0 = o3d.geometry.PointCloud()\n",
    "pcd_kp_g_0.points = o3d.utility.Vector3dVector(kpts_g_0)\n",
    "pcd_kp_g_0.paint_uniform_color([0, 0, 1])\n",
    "pcd_kp_g_1 = o3d.geometry.PointCloud()\n",
    "pcd_kp_g_1.points = o3d.utility.Vector3dVector(kpts_g_1)\n",
    "pcd_kp_g_1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "points = np.concatenate((np.array(pcd_kp_g_0.points),np.array(pcd_kp_g_1.points)), axis=0) # >> pcd_kp0에 pcd_kp1를 이어 붙힘\n",
    "lines = []\n",
    "colors = []\n",
    "for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "    lines.append([match, mutual1[idx] + len(kpts0)])\n",
    "    # lines.append([match, mutual1[idx] + len(kpts_g_0)])\n",
    "    point1 = kpts_g_0[match]\n",
    "    point2 = kpts_g_1[mutual1[idx]]\n",
    "    if np.linalg.norm(point1 - point2) < 1.0:\n",
    "        colors.append([0, 1, 0])\n",
    "    else: \n",
    "        colors.append([1, 0, 0])\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector((points)),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([pcd0,pcd1,line_set])\n",
    "\n",
    "# o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])\n",
    "o3d.visualization.draw_geometries([pcd_kp_g_0, pcd_kp_g_1, line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kpts0.shape, kpts_g_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dataset.get_divided_data(2)\n",
    "print(pred['keypoints0'].shape, pred['cloud0'].shape, pred['scores0'].shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매칭\n",
    "# pred = dataset.get_matching_data(12)\n",
    "# pred = dataset.get_matching_data(13)\n",
    "# pred = dataset.get_matching_data(12)\n",
    "for p in pred:\n",
    "    if type(pred[p]) == torch.Tensor:\n",
    "        pred[p] = pred[p].to(device)\n",
    "print(pred['keypoints0'].shape, pred['keypoints1'].shape, pred['descriptors0'].shape, pred['descriptors1'].shape)\n",
    "\n",
    "data = net.module.infer_mdgat(pred, [pred['keypoints0'].shape[1]//2, None, pred['keypoints0'].shape[1]//2, None, pred['keypoints0'].shape[1]//4, None, pred['keypoints0'].shape[1]//4, None], [pred['keypoints1'].shape[1]//2, None, pred['keypoints1'].shape[1]//2, None, pred['keypoints1'].shape[1]//4, None, pred['keypoints1'].shape[1]//4, None])\n",
    "pred = {**pred, **data}\n",
    "print(\"pred's keys: \", pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 디스크립터 추출\n",
    "net.double().eval()\n",
    "\n",
    "for i in range(dataset.divided_seq_num - 1):\n",
    "    pred = dataset.get_divided_data(i)\n",
    "    for p in pred:\n",
    "        pred[p] = pred[p].to(device)\n",
    "    data = net.module.infer_desc(pred)\n",
    "    for d in data:\n",
    "        data[d] = data[d].detach().cpu()\n",
    "    dataset.push_descriptor(i, data['desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 매칭\n",
    "# pred = dataset.get_matching_data(12)\n",
    "pred = dataset.get_matching_data(13)\n",
    "# pred = dataset.get_matching_data(12)\n",
    "for p in pred:\n",
    "    if type(pred[p]) == torch.Tensor:\n",
    "        pred[p] = pred[p].to(device)\n",
    "print(pred['keypoints0'].shape, pred['keypoints1'].shape, pred['descriptors0'].shape, pred['descriptors1'].shape)\n",
    "\n",
    "data = net.module.infer_mdgat(pred, [pred['keypoints0'].shape[1]//2, None, pred['keypoints0'].shape[1]//2, None, pred['keypoints0'].shape[1]//4, None, pred['keypoints0'].shape[1]//4, None], [pred['keypoints1'].shape[1]//2, None, pred['keypoints1'].shape[1]//2, None, pred['keypoints1'].shape[1]//4, None, pred['keypoints1'].shape[1]//4, None])\n",
    "pred = {**pred, **data}\n",
    "print(\"pred's keys: \", pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "matches0, matches1, conf = pred['matches0'][0].cpu().detach().numpy(), pred['matches1'][0].cpu().detach().numpy(), pred['matching_scores0'][0].cpu().detach().numpy()\n",
    "valid = matches0 > -1\n",
    "mkpts0 = kpts0[valid]\n",
    "mkpts1 = kpts1[matches0[valid]]\n",
    "\n",
    "mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "mutual1 = matches0[mutual0]\n",
    "x = np.ones(len(matches1)) == 1\n",
    "x[mutual1] = False\n",
    "valid1 = matches1 > -1\n",
    "\n",
    "mconf = conf[valid]\n",
    "\n",
    "matches_gt, matches_gt1 = pred['gt_matches0'], pred['gt_matches1']\n",
    "matches_gt[matches_gt == len(matches_gt1)] = -1\n",
    "matches_gt1[matches_gt1 == len(matches_gt)] = -1\n",
    "valid_gt = matches_gt > -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(matches0.shape, matches1.shape, conf.shape) # >> (3328,) (256,) (3328,)\n",
    "\n",
    "print(matches0[669]) # matches0의 669번째 인덱스와의 매칭 결과 >> 1\n",
    "\n",
    "print(matches1[:]) # matches1의 전체 결과 >> [  -1  669   -1  677 ...], 즉 matches1의 1번째 포인트가 matches0의 669번째 포인트와 매칭됨\n",
    "\n",
    "print(mutual0) # >> [   9   10   13   15 ...]\n",
    "\n",
    "print(mutual1) # >> [248 245  20 255 106 ...]\n",
    "\n",
    "print(matches0[9], matches1[248]) # >> 248, 9, 즉 mutual0[i]와 mutual1[i]의 idx끼리 매칭 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "pcd_kp0 = o3d.geometry.PointCloud()\n",
    "pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "pcd_kp1 = o3d.geometry.PointCloud()\n",
    "pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "points = np.concatenate((np.array(pcd_kp0.points),np.array(pcd_kp1.points)), axis=0) # >> pcd_kp0에 pcd_kp1를 이어 붙힘\n",
    "lines = []\n",
    "for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "    # lines.append([match, match + 1])\n",
    "    # lines.append([mutual1[idx] + len(kpts0), mutual1[idx] + len(kpts0)])\n",
    "    lines.append([match, mutual1[idx] + len(kpts0)])\n",
    "colors = [[0, 1, 0] for _ in range(len(lines))] # lines are shown in green\n",
    "# print(points[lines[0][0]], points[lines[0][1]])\n",
    "# print(pcd_kp0.points[lines[0][0]], pcd_kp1.points[lines[0][1] - len(pcd_kp0.points)])\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector((points)),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([pcd0,pcd1,line_set])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = 2.0\n",
    "\n",
    "# 시각화\n",
    "kpts0, kpts1 = pred['keypoints0'][0].cpu().numpy(), pred['keypoints1'][0].cpu().numpy()\n",
    "pcd_kp0 = o3d.geometry.PointCloud()\n",
    "pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "pcd_kp1 = o3d.geometry.PointCloud()\n",
    "pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "desc0 = pred['descriptors0'][0].cpu().detach().numpy().T\n",
    "desc1 = pred['descriptors1'][0].cpu().detach().numpy().T\n",
    "dists = cdist(desc0, desc1)\n",
    "min0 = np.argmin(dists, axis=0)\n",
    "min1 = np.argmin(dists, axis=1)\n",
    "min0v = np.min(dists, axis=1)\n",
    "min0f = min1[min0v < ttt]\n",
    "match0, match1 = -1 * np.ones((len(desc0)), dtype=np.int16), -1 * np.ones((len(desc1)), dtype=np.int16)\n",
    "match0[min0v < ttt] = min0f\n",
    "min1v = np.min(dists, axis=0)\n",
    "min1f = min0[min1v < ttt]\n",
    "match1[min1v < ttt] = min1f\n",
    "mutual0 = np.arange(len(matches0))[valid] == matches1[matches0[valid]]\n",
    "mutual0 = np.arange(len(matches0))[valid][mutual0]\n",
    "mutual1 = matches0[mutual0]\n",
    "\n",
    "# 시각화\n",
    "pcd_kp0 = o3d.geometry.PointCloud()\n",
    "pcd_kp0.points = o3d.utility.Vector3dVector(kpts0)\n",
    "pcd_kp0.paint_uniform_color([1, 0, 0])\n",
    "pcd_kp1 = o3d.geometry.PointCloud()\n",
    "pcd_kp1.points = o3d.utility.Vector3dVector(kpts1)\n",
    "pcd_kp1.paint_uniform_color([0, 1, 0])\n",
    "\n",
    "points = np.concatenate((np.array(pcd_kp0.points),np.array(pcd_kp1.points)), axis=0) # >> pcd_kp0에 pcd_kp1를 이어 붙힘\n",
    "lines = []\n",
    "for idx, match in enumerate(mutual0): # mutual0의 값\n",
    "    lines.append([match, mutual1[idx] + len(kpts0)])\n",
    "colors = [[0, 1, 0] for _ in range(len(lines))] # lines are shown in green\n",
    "# print(points[lines[0][0]], points[lines[0][1]])\n",
    "# print(pcd_kp0.points[lines[0][0]], pcd_kp1.points[lines[0][1] - len(pcd_kp0.points)])\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector((points)),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([pcd0,pcd1,line_set])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_kp0, pcd_kp1, line_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mutual0)\n",
    "print(mutual1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
