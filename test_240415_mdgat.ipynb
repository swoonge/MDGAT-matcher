{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys, signal,rospy, argparse, csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.distance import cdist\n",
    "import copy, pickle\n",
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "from open3d_ros_helper import open3d_ros_helper as orh\n",
    "from geometry_msgs.msg import Pose, PoseArray, Point # PoseArray, Pose\n",
    "from std_msgs.msg import ColorRGBA\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "from visualization_msgs.msg import Marker\n",
    "\n",
    "from models.mdgat import MDGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Point cloud matching and pose evaluation',\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "opt = argparse.Namespace(\n",
    "    slam_dir = '/media/vision/Seagate/DataSets/KRGM/kitti/',\n",
    "    data_folder = 'harris_3D',\n",
    "    local_global = False,\n",
    "    seq_num = '00',\n",
    "    visualize = False,\n",
    "    vis_line_width = 0.2,\n",
    "    calculate_pose = True,\n",
    "    learning_rate = 0.0001,\n",
    "    batch_size = 1,\n",
    "    train_path = './KITTI/',\n",
    "    model_out_path = './models/checkpoint',\n",
    "    memory_is_enough = True,\n",
    "    local_rank = 0,\n",
    "    txt_path = './KITTI/preprocess-random-full',\n",
    "    keypoints_path = './KITTI/keypoints/tsf_256_FPFH_16384-512-k1k16-2d-nonoise',\n",
    "    resume_model = './checkpoint/kitti/mdgat-l9-gap_loss-pointnetmsg-04_01_19_32/train_step3/nomutualcheck-mdgat-batch16-gap_loss-pointnetmsg-USIP-04_01_19_32/best_model_epoch_221(val_loss0.31414552026539594).pth',\n",
    "    loss_method = 'triplet_loss',\n",
    "    net = 'mdgat',\n",
    "    mutual_check = False,\n",
    "    k = [128, None, 128, None, 64, None, 64, None],\n",
    "    l = 9,\n",
    "    descriptor = 'pointnetmsg',\n",
    "    keypoints = 'USIP',\n",
    "    ensure_kpts_num = False,\n",
    "    max_keypoints = -1,\n",
    "    match_threshold = 0.2,\n",
    "    threshold = 0.5,\n",
    "    triplet_loss_gamma = 0.5,\n",
    "    sinkhorn_iterations = 20,\n",
    "    train_step = 3,\n",
    "\n",
    "    fpfh_normal_radiuse = 0.3,\n",
    "    fpfh_descriptors_radiuse = 1.0,\n",
    "    seq_list = [0],\n",
    "    mdgat_path = './KITTI',\n",
    "    kitti_path = '/media/vision/Seagate/DataSets/kitti/dataset/sequences',\n",
    "    transform_opt = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_sigint(signal, frame):\n",
    "    print(\"\\n ---cancel by user---\")\n",
    "    sys.exit(0)\n",
    "\n",
    "def model_inference(net, data, device):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        data['keypoints0'] = data['keypoints0'].to(device)\n",
    "        data['keypoints1'] = data['keypoints1'].to(device)\n",
    "        data['cloud0'] = data['cloud0'].to(device)\n",
    "        data['cloud1'] = data['cloud1'].to(device)\n",
    "        data['scores0'] = data['cloud0'].to(device)\n",
    "        data['scores1'] = data['cloud1'].to(device)\n",
    "\n",
    "        output = net(data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset():\n",
    "    def __init__(self, args) -> None:\n",
    "        self.gt_seq = args.seq_num\n",
    "        self.data_folder = args.data_folder\n",
    "\n",
    "        self.dir_SLAM_path = args.slam_dir + self.data_folder +\"/\"\n",
    "        self.pub_SLAM_map = rospy.Publisher('/slam_map', PointCloud2, queue_size=100)\n",
    "        self.pub_SLAM_keypoints = rospy.Publisher('/slam_keypoints', PointCloud2, queue_size=100)\n",
    "        self.pub_SLAM_keypoints_local = rospy.Publisher('/slam_keypoints_local', PointCloud2, queue_size=100)\n",
    "        self.pub_SLAM_poses = rospy.Publisher('/slam_odom', PoseArray, queue_size=100)\n",
    "        # self.pub_matching_line = rospy.Publisher('/matching_line', Marker, queue_size=100)\n",
    "\n",
    "        self.poses = []\n",
    "        self.dense_scans = []\n",
    "        self.keypoints = []\n",
    "        self.descriptors = []\n",
    "        self.local_graph_range = [0, 0]\n",
    "\n",
    "        self._get_SLAM_poses()\n",
    "        self._get_dense_frames()\n",
    "        self._get_keypoints()\n",
    "        # self._get_descriptors()\n",
    "        print(\"[Load] SLAM data complite\")\n",
    "\n",
    "    def _get_SLAM_poses(self):\n",
    "        with open(file=os.path.join(self.dir_SLAM_path, \"Poses_kitti_\" + self.gt_seq + \".pickle\"), mode='rb') as f:\n",
    "            self.poses = pickle.load(f)\n",
    "        print(\"poses: \", len(self.poses))\n",
    "\n",
    "    def _get_dense_frames(self):\n",
    "        with open(file=os.path.join(self.dir_SLAM_path, \"DenseFrames_kitti_\" + self.gt_seq + \".pickle\"), mode='rb') as f:\n",
    "            self.dense_scans = pickle.load(f)\n",
    "\n",
    "    def _get_keypoints(self):\n",
    "        with open(file=os.path.join(self.dir_SLAM_path, \"keyPoints_kitti_\" + self.gt_seq + \".pickle\"), mode='rb') as f:\n",
    "            self.keypoints = pickle.load(f)\n",
    "\n",
    "    def _get_descriptors(self):\n",
    "        with open(file=os.path.join(self.dir_SLAM_path, \"Descriptors_FPFH_kitti_\" + self.gt_seq + \".pickle\"), mode='rb') as f:\n",
    "            self.descriptors = pickle.load(f)\n",
    "\n",
    "    def set_current_pose_idx(self, idx):\n",
    "        if idx >= len(self.poses):\n",
    "            idx = len(self.poses) - 1\n",
    "        self.local_graph_range[1] = idx\n",
    "\n",
    "        kp_num = 0\n",
    "        for pc_idx in range(self.local_graph_range[1], 0, -1):\n",
    "            kp_num += len(self.keypoints[pc_idx])\n",
    "            if kp_num > 150:\n",
    "                self.local_graph_range[0] = pc_idx\n",
    "                break\n",
    "\n",
    "    def _keypoints_l2_matching(self):\n",
    "        local_keypoints = np.zeros((1,3))\n",
    "        local_descriptors = np.zeros((1,33))\n",
    "        global_keypoints = np.zeros((1,3))\n",
    "        global_descriptors = np.zeros((1,33))\n",
    "\n",
    "        for idx in range(self.local_graph_range[0], self.local_graph_range[1]):\n",
    "            if self.keypoints[idx].shape[0]: local_keypoints = np.vstack((local_keypoints, self.keypoints[idx]))\n",
    "            if len(self.descriptors[idx]): local_descriptors = np.vstack((local_descriptors, self.descriptors[idx]))\n",
    "        for idx in range(self.local_graph_range[0]):\n",
    "            if self.keypoints[idx].shape[0]: global_keypoints = np.vstack((global_keypoints, self.keypoints[idx]))\n",
    "            if len(self.descriptors[idx]): global_descriptors = np.vstack((global_descriptors, self.descriptors[idx]))\n",
    "        \n",
    "        local_keypoints = local_keypoints[1:]\n",
    "        local_descriptors = local_descriptors[1:]\n",
    "        global_keypoints = global_keypoints[1:]\n",
    "        global_descriptors = global_descriptors[1:]\n",
    "\n",
    "        threshold = 30.0\n",
    "        distance_matrix = cdist(local_descriptors, global_descriptors)\n",
    "        matched_indices = np.where((distance_matrix <= threshold))\n",
    "        # matched_indices = np.where((distance_matrix <= threshold) & (distance_matrix != 0.0))\n",
    "        matched_keypoints1 = matched_indices[0]\n",
    "        matched_keypoints2 = matched_indices[1]\n",
    "\n",
    "        self.matching_line = Marker()\n",
    "        for i in range(len(matched_keypoints1)):\n",
    "            self.matching_line.header.frame_id = \"/camera_init\"\n",
    "            self.matching_line.type = Marker.LINE_LIST\n",
    "            self.matching_line.action = Marker.ADD\n",
    "            line = Point(x=local_keypoints[matched_keypoints1[i]][0], y=local_keypoints[matched_keypoints1[i]][1], z=local_keypoints[matched_keypoints1[i]][2])\n",
    "            self.matching_line.points.append(line)\n",
    "            line = Point(x=global_keypoints[matched_keypoints2[i]][0], y=global_keypoints[matched_keypoints2[i]][1], z=global_keypoints[matched_keypoints2[i]][2])\n",
    "            self.matching_line.points.append(line)\n",
    "            self.matching_line.colors.append(ColorRGBA(1.0,0,0,1.0))\n",
    "            self.matching_line.colors.append(ColorRGBA(1.0,0,0,1.0))\n",
    "            self.matching_line.scale.x = 0.01\n",
    "\n",
    "        # self.pub_matching_line.publish(self.matching_line)\n",
    "\n",
    "        print(matched_keypoints1)\n",
    "        print(matched_keypoints2)\n",
    "    \n",
    "    def make_map(self):        \n",
    "        #slam_keypoints\n",
    "        self.keypoints_msg = PointCloud2()\n",
    "        self.keypoints_local_msg = PointCloud2()\n",
    "        keypoints_msg_pc = o3d.geometry.PointCloud()\n",
    "        keypoints_msg_pc_local = o3d.geometry.PointCloud()\n",
    "        \n",
    "        for pc_idx in range(self.local_graph_range[1]):\n",
    "            pc_add = o3d.geometry.PointCloud()\n",
    "            pc_add.points = o3d.utility.Vector3dVector(self.keypoints[pc_idx])\n",
    "\n",
    "            if pc_idx >= self.local_graph_range[0]: keypoints_msg_pc_local += pc_add\n",
    "            else: keypoints_msg_pc += pc_add\n",
    "               \n",
    "        self.keypoints_msg = orh.o3dpc_to_rospc(keypoints_msg_pc)\n",
    "        self.keypoints_msg.header.frame_id = \"/camera_init\"\n",
    "        self.keypoints_local_msg = orh.o3dpc_to_rospc(keypoints_msg_pc_local)\n",
    "        self.keypoints_local_msg.header.frame_id = \"/camera_init\"\n",
    "        \n",
    "        self.pub_SLAM_keypoints.publish(self.keypoints_msg)\n",
    "        self.pub_SLAM_keypoints_local.publish(self.keypoints_local_msg)\n",
    "        \n",
    "        # slam_poses\n",
    "        self.keyposes_msg = PoseArray()\n",
    "        for pose in self.poses:\n",
    "            odom_msg_chach = Pose()\n",
    "            odom_msg_chach.position.x = pose[0]\n",
    "            odom_msg_chach.position.y = pose[1]\n",
    "            odom_msg_chach.position.z = pose[2]\n",
    "            odom_msg_chach.orientation.x = pose[3]\n",
    "            odom_msg_chach.orientation.y = pose[4]\n",
    "            odom_msg_chach.orientation.z = pose[5]\n",
    "            odom_msg_chach.orientation.w = pose[6]\n",
    "            self.keyposes_msg.poses.append(odom_msg_chach)\n",
    "        self.keyposes_msg.header.frame_id = \"/camera_init\"\n",
    "        self.pub_SLAM_poses.publish(self.keyposes_msg)\n",
    "\n",
    "        # slam_map\n",
    "        self.map_msg = PointCloud2()\n",
    "        map_msg_pc = o3d.geometry.PointCloud()\n",
    "        for pc in self.dense_scans:\n",
    "            pc_chach = o3d.geometry.PointCloud()\n",
    "            pc_chach.points = o3d.utility.Vector3dVector(np.array(pc))\n",
    "            map_msg_pc += pc_chach\n",
    "        self.map_msg = orh.o3dpc_to_rospc(map_msg_pc.voxel_down_sample(voxel_size=0.3))\n",
    "        self.map_msg.header.frame_id = \"/camera_init\"\n",
    "        self.pub_SLAM_map.publish(self.map_msg)\n",
    "        \n",
    "    def pub_map(self):\n",
    "        self.pub_SLAM_keypoints.publish(self.keypoints_msg)\n",
    "        self.pub_SLAM_keypoints_local.publish(self.keypoints_local_msg)\n",
    "        self.pub_SLAM_poses.publish(self.keyposes_msg)\n",
    "        self.pub_SLAM_map.publish(self.map_msg)\n",
    "        print(\"pub complite\")\n",
    "    \n",
    "    def get_data(self):\n",
    "        kp0 = np.empty((0, 3))\n",
    "        kp1 = np.empty((0, 3))\n",
    "        pc0 = o3d.geometry.PointCloud()\n",
    "        pc1 = o3d.geometry.PointCloud()\n",
    "        \n",
    "        for pc_idx in range(self.local_graph_range[1]):\n",
    "            pc_chach = o3d.geometry.PointCloud()\n",
    "            pc_chach.points = o3d.utility.Vector3dVector(np.array(self.dense_scans[pc_idx]))\n",
    "\n",
    "            if pc_idx >= self.local_graph_range[0]:\n",
    "                # kp1 += self.keypoints[pc_idx]\n",
    "                kp1 = np.concatenate((kp1, self.keypoints[pc_idx]), axis=0)\n",
    "                pc1 += pc_chach\n",
    "            else: \n",
    "                kp0 = np.concatenate((kp0, self.keypoints[pc_idx]), axis=0)\n",
    "                pc0 += pc_chach\n",
    "        \n",
    "        pc0 = pc0.voxel_down_sample(voxel_size=0.2)\n",
    "        pc1 = pc1.voxel_down_sample(voxel_size=0.2)\n",
    "\n",
    "        \n",
    "\n",
    "        pc0 = np.array(pc0.points)\n",
    "        pc1 = np.array(pc1.points)\n",
    "\n",
    "        print(pc0.shape, pc1.shape)\n",
    "\n",
    "        pc0_ones = np.ones((pc0.shape[0], 1))\n",
    "        pc1_ones = np.ones((pc1.shape[0], 1))\n",
    "\n",
    "        print(pc0.shape, pc1.shape)\n",
    "\n",
    "        pc0 = np.concatenate((pc0, pc0_ones), axis=1)[:-(pc0.size % 8)]\n",
    "        pc1 = np.concatenate((pc1, pc1_ones), axis=1)[:-(pc1.size % 8)]\n",
    "\n",
    "        pc0 = pc0.reshape((-1, 8))\n",
    "        pc1 = pc1.reshape((-1, 8))\n",
    "\n",
    "        print(pc0.shape, pc1.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        kp0_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in kp0]) \n",
    "        kp1_np = np.array([(kp[0], kp[1], kp[2], 1) for kp in kp1])\n",
    "\n",
    "        kp0_np = torch.tensor(kp0_np, dtype=torch.double)\n",
    "        kp1_np = torch.tensor(kp1_np, dtype=torch.double)\n",
    "\n",
    "        kp0_np = kp0_np[:, :3]\n",
    "        kp1_np = kp1_np[:, :3]\n",
    "\n",
    "        scores0 = np.ones_like(kp0_np[:,:1])\n",
    "        scores1 = np.ones_like(kp1_np[:,:1])\n",
    "\n",
    "        pc0, pc1 = torch.tensor(pc0, dtype=torch.double), torch.tensor(pc1, dtype=torch.double)\n",
    "\n",
    "        #   File \"/home/vision/ADD_prj/MDGAT-matcher/models/mdgat.py\", line 118, in forward\n",
    "            # B, _, _ = xyz.shape\n",
    "            # ValueError: not enough values to unpack (expected 3, got 2)\n",
    "        # 라는 오류가 나는데, 이건 원래 배치가 들어가면 앞에 배치사이즈가 나와야 되는데, 그게 안나와서 그런거임. 즉 배치가 1이어도 앞에 배치사이즈가 나와야함.\n",
    "\n",
    "        kp0_np = np.expand_dims(kp0_np, axis=0)\n",
    "        kp0_tensor = torch.tensor(kp0_np, dtype=torch.double)\n",
    "        kp1_np = np.expand_dims(kp1_np, axis=0)\n",
    "        kp1_tensor = torch.tensor(kp1_np, dtype=torch.double)\n",
    "        # scores0 = np.expand_dims(scores0, axis=0)\n",
    "        scores0_tensor = torch.tensor(scores0, dtype=torch.double)\n",
    "        # scores1 = np.expand_dims(scores1, axis=0)\n",
    "        scores1_tensor = torch.tensor(scores1, dtype=torch.double)\n",
    "        pc0 = pc0.unsqueeze(0)\n",
    "        pc1 = pc0.unsqueeze(0)\n",
    "\n",
    "\n",
    "        return{\n",
    "            'keypoints0': kp0_tensor,\n",
    "            'keypoints1': kp1_tensor,\n",
    "            'cloud0': pc0,\n",
    "            'cloud1': pc1,\n",
    "            'scores0' : scores0_tensor,\n",
    "            'scores1' : scores1_tensor\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _signal.default_int_handler(signalnum, frame, /)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "signal.signal(signal.SIGINT, handle_sigint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poses:  929\n",
      "[Load] SLAM data complite\n"
     ]
    },
    {
     "ename": "ROSInitException",
     "evalue": "time is not initialized. Have you called init_node()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mROSInitException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset new pose idx >> \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m Data\u001b[38;5;241m.\u001b[39mset_current_pose_idx(\u001b[38;5;28mint\u001b[39m(pose))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m path_checkpoint \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mresume_model  \n\u001b[1;32m      8\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(path_checkpoint, map_location\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m})  \n",
      "Cell \u001b[0;32mIn[23], line 111\u001b[0m, in \u001b[0;36mdataset.make_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pc_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_graph_range[\u001b[38;5;241m0\u001b[39m]: keypoints_msg_pc_local \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pc_add\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: keypoints_msg_pc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pc_add\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoints_msg \u001b[38;5;241m=\u001b[39m \u001b[43morh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo3dpc_to_rospc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints_msg_pc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoints_msg\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mframe_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/camera_init\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeypoints_local_msg \u001b[38;5;241m=\u001b[39m orh\u001b[38;5;241m.\u001b[39mo3dpc_to_rospc(keypoints_msg_pc_local)\n",
      "File \u001b[0;32m~/anaconda3/envs/mdgat/lib/python3.10/site-packages/open3d_ros_helper/open3d_ros_helper.py:340\u001b[0m, in \u001b[0;36mo3dpc_to_rospc\u001b[0;34m(o3dpc, frame_id, stamp)\u001b[0m\n\u001b[1;32m    337\u001b[0m     rospc\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mframe_id \u001b[38;5;241m=\u001b[39m frame_id\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stamp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     rospc\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mstamp \u001b[38;5;241m=\u001b[39m \u001b[43mrospy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     rospc\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mstamp \u001b[38;5;241m=\u001b[39m stamp\n",
      "File \u001b[0;32m/opt/ros/noetic/lib/python3/dist-packages/rospy/rostime.py:155\u001b[0m, in \u001b[0;36mTime.now\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnow\u001b[39m():\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Create new L{Time} instance representing current time. This\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    can either be wall-clock time or a simulated clock. It is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    @rtype: L{Time}\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_rostime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/ros/noetic/lib/python3/dist-packages/rospy/rostime.py:190\u001b[0m, in \u001b[0;36mget_rostime\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03mGet the current time as a L{Time} object    \u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m@return: current time as a L{rospy.Time} object\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m@rtype: L{Time}\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _rostime_initialized:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m rospy\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mROSInitException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime is not initialized. Have you called init_node()?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _rostime_current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# initialize with sim time\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _rostime_current\n",
      "\u001b[0;31mROSInitException\u001b[0m: time is not initialized. Have you called init_node()?"
     ]
    }
   ],
   "source": [
    "# set dataset\n",
    "Data = dataset(args=opt)\n",
    "pose = input(\"set new pose idx >> \")\n",
    "Data.set_current_pose_idx(int(pose))\n",
    "Data.make_map()\n",
    "\n",
    "path_checkpoint = opt.resume_model  \n",
    "checkpoint = torch.load(path_checkpoint, map_location={'cuda:2':'cuda:0'})  \n",
    "lr = checkpoint['lr_schedule']\n",
    "config = {\n",
    "    'net': {\n",
    "        'sinkhorn_iterations': opt.sinkhorn_iterations,\n",
    "        'match_threshold': opt.match_threshold,\n",
    "        # 'lr': lr,\n",
    "        'lr': opt.learning_rate,\n",
    "        'loss_method': opt.loss_method,\n",
    "        'k': opt.k,\n",
    "        'descriptor': opt.descriptor,\n",
    "        'mutual_check': opt.mutual_check,\n",
    "        'triplet_loss_gamma': opt.triplet_loss_gamma,\n",
    "        'train_step':opt.train_step,\n",
    "        'L':opt.l\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"config: \", config)\n",
    "\n",
    "net = MDGAT(config.get('net', {}))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=config.get('net', {}).get('lr'))\n",
    "net = torch.nn.DataParallel(net)\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "device=torch.device('cuda:{}'.format(opt.local_rank))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Data.get_data()\n",
    "print(pred.keys())\n",
    "print(pred['keypoints0'].shape, pred['keypoints1'].shape, pred['cloud0'].shape, pred['cloud1'].shape, pred['scores0'].shape, pred['scores1'].shape)\n",
    "print(\"get data complite\")\n",
    "\n",
    "data = model_inference(net, pred, device)\n",
    "\n",
    "print(data)\n",
    "\n",
    "while True:\n",
    "    pose = input(\"map massage publist again? or set new pose idx >> \")\n",
    "    if pose != \"\":\n",
    "        Data.set_current_pose_idx(int(pose))\n",
    "        Data.make_map()\n",
    "        # Data._keypoints_l2_matching()\n",
    "    Data.pub_map()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdgat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
